{
 "metadata": {
  "language": "lua",
  "name": "",
  "signature": "sha256:4182586f91e2717c5843dbf150bfdddf9d42c41c5d16f9255a5bf52040c35f14"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Train a ConvNet to recognize objects using the CIFAR dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this tutorial, we train a ConvNet from scratch to do object recognition over 10 classes.\n",
      "You would learn how to use Torch's neural network package and optim package to train a network."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-- require the necessary packages\n",
      "require 'torch'\n",
      "require 'nn'\n",
      "require 'optim'\n",
      "require 'image'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-- manually define the class-names in CIFAR-10 in a lua table\n",
      "classes = {'airplane', 'automobile', 'bird', 'cat',\n",
      "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck'}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-- define model to train\n",
      "model = nn.Sequential()\n",
      "-- stage 1 : mean+std normalization -> filter bank -> squashing -> max pooling\n",
      "model:add(nn.SpatialConvolutionMM(3,32,5,5))\n",
      "model:add(nn.ReLU())\n",
      "model:add(nn.SpatialMaxPooling(2, 2, 2, 2))\n",
      "-- stage 2 : filter bank -> squashing -> max pooling\n",
      "model:add(nn.SpatialConvolutionMM(32,32,5,5))\n",
      "model:add(nn.ReLU())\n",
      "model:add(nn.SpatialMaxPooling(2, 2, 2, 2))\n",
      "-- stage 3 : standard 2-layer neural network\n",
      "model:add(nn.View(32*5*5))\n",
      "model:add(nn.Linear(32*5*5, 128))\n",
      "model:add(nn.ReLU())\n",
      "model:add(nn.Linear(128,#classes))\n",
      "model:add(nn.LogSoftMax())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(model:__tostring())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-- retrieve parameters and gradients. this helps us to use the optim package\n",
      "parameters,gradParameters = model:getParameters()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-- loss function: negative log-likelihood\n",
      "criterion = nn.ClassNLLCriterion()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-- get/create dataset\n",
      "--\n",
      "batchSize = 1 -- sets the mini-Batch size\n",
      "\n",
      "if fullDataset then\n",
      "   trsize = 50000\n",
      "   tesize = 10000\n",
      "else\n",
      "   trsize = 2000\n",
      "   tesize = 1000\n",
      "end\n",
      "\n",
      "-- load dataset\n",
      "trainData = {\n",
      "   data = torch.Tensor(50000, 3072),\n",
      "   labels = torch.Tensor(50000),\n",
      "   size = function() return trsize end\n",
      "}\n",
      "for i = 0,4 do\n",
      "   subset = torch.load('cifar-10-batches-t7/data_batch_' .. (i+1) .. '.t7', 'ascii')\n",
      "   trainData.data[{ {i*10000+1, (i+1)*10000} }] = subset.data:t()\n",
      "   trainData.labels[{ {i*10000+1, (i+1)*10000} }] = subset.labels\n",
      "end\n",
      "trainData.labels = trainData.labels + 1\n",
      "\n",
      "subset = torch.load('cifar-10-batches-t7/test_batch.t7', 'ascii')\n",
      "testData = {\n",
      "   data = subset.data:t():double(),\n",
      "   labels = subset.labels[1]:double(),\n",
      "   size = function() return tesize end\n",
      "}\n",
      "testData.labels = testData.labels + 1\n",
      "\n",
      "-- resize dataset (if not using the full dataset)\n",
      "trainData.data = trainData.data[{ {1,trsize} }]\n",
      "trainData.labels = trainData.labels[{ {1,trsize} }]\n",
      "\n",
      "testData.data = testData.data[{ {1,tesize} }]\n",
      "testData.labels = testData.labels[{ {1,tesize} }]\n",
      "\n",
      "-- reshape data\n",
      "trainData.data = trainData.data:reshape(trsize,3,32,32)\n",
      "testData.data = testData.data:reshape(tesize,3,32,32)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-- preprocess/normalize train/test sets\n",
      "-- preprocess trainSet\n",
      "normalization = nn.SpatialContrastiveNormalization(1, image.gaussian1D(7))\n",
      "for i = 1,trainData:size() do\n",
      "   -- rgb -> yuv\n",
      "   local rgb = trainData.data[i]\n",
      "   local yuv = image.rgb2yuv(rgb)\n",
      "   -- normalize y locally:\n",
      "   yuv[1] = normalization(yuv[{{1}}])\n",
      "   trainData.data[i] = yuv\n",
      "end\n",
      "-- normalize u globally:\n",
      "mean_u = trainData.data[{ {},2,{},{} }]:mean()\n",
      "std_u = trainData.data[{ {},2,{},{} }]:std()\n",
      "trainData.data[{ {},2,{},{} }]:add(-mean_u)\n",
      "trainData.data[{ {},2,{},{} }]:div(-std_u)\n",
      "-- normalize v globally:\n",
      "mean_v = trainData.data[{ {},3,{},{} }]:mean()\n",
      "std_v = trainData.data[{ {},3,{},{} }]:std()\n",
      "trainData.data[{ {},3,{},{} }]:add(-mean_v)\n",
      "trainData.data[{ {},3,{},{} }]:div(-std_v)\n",
      "\n",
      "-- preprocess testSet\n",
      "for i = 1,testData:size() do\n",
      "   -- rgb -> yuv\n",
      "   local rgb = testData.data[i]\n",
      "   local yuv = image.rgb2yuv(rgb)\n",
      "   -- normalize y locally:\n",
      "   yuv[{1}] = normalization(yuv[{{1}}])\n",
      "   testData.data[i] = yuv\n",
      "end\n",
      "-- normalize u globally:\n",
      "testData.data[{ {},2,{},{} }]:add(-mean_u)\n",
      "testData.data[{ {},2,{},{} }]:div(-std_u)\n",
      "-- normalize v globally:\n",
      "testData.data[{ {},3,{},{} }]:add(-mean_v)\n",
      "testData.data[{ {},3,{},{} }]:div(-std_v)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-- this matrix records the current confusion across classes\n",
      "confusion = optim.ConfusionMatrix(classes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-- define training and testing functions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-- training function\n",
      "function train(dataset)\n",
      "   -- epoch tracker\n",
      "   epoch = epoch or 1\n",
      "\n",
      "   -- do one epoch\n",
      "   print('<trainer> on training set:')\n",
      "   print(\"<trainer> online epoch # \" .. epoch .. ' [batchSize = ' .. batchSize .. ']')\n",
      "   for t = 1,dataset:size(),batchSize do\n",
      "\n",
      "      -- create mini batch\n",
      "      local inputs = {}\n",
      "      local targets = {}\n",
      "      for i = t,math.min(t+batchSize-1,dataset:size()) do\n",
      "         -- load new sample\n",
      "         local input = dataset.data[i]\n",
      "         local target = dataset.labels[i]\n",
      "         table.insert(inputs, input)\n",
      "         table.insert(targets, target)\n",
      "      end\n",
      "\n",
      "      -- create closure to evaluate f(X) and df/dX\n",
      "      local feval = function(x)\n",
      "                       -- get new parameters\n",
      "                       if x ~= parameters then\n",
      "                          parameters:copy(x)\n",
      "                       end\n",
      "\n",
      "                       -- reset gradients\n",
      "                       gradParameters:zero()\n",
      "\n",
      "                       -- f is the average of all criterions\n",
      "                       local f = 0\n",
      "\n",
      "                       -- evaluate function for complete mini batch\n",
      "                       for i = 1,#inputs do\n",
      "                          -- estimate f\n",
      "                          local output = model:forward(inputs[i])\n",
      "                          local err = criterion:forward(output, targets[i])\n",
      "                          f = f + err\n",
      "\n",
      "                          -- estimate df/dW\n",
      "                          local df_do = criterion:backward(output, targets[i])\n",
      "                          model:backward(inputs[i], df_do)\n",
      "\n",
      "                          -- update confusion\n",
      "                          confusion:add(output, targets[i])                        \n",
      "                       end\n",
      "\n",
      "                       -- normalize gradients and f(X)\n",
      "                       gradParameters:div(#inputs)\n",
      "                       f = f/#inputs\n",
      "\n",
      "                       -- return f and df/dX\n",
      "                       return f,gradParameters\n",
      "                    end\n",
      "\n",
      "\n",
      "      config = config or {learningRate = 1e-3,\n",
      "              weightDecay = 0,\n",
      "                momentum = 0,\n",
      "              learningRateDecay = 5e-7}\n",
      "      optim.sgd(feval, parameters, config)\n",
      "   end\n",
      "\n",
      "   -- print confusion matrix\n",
      "   print(confusion)\n",
      "   confusion:zero()\n",
      "\n",
      "   -- next epoch\n",
      "   epoch = epoch + 1\n",
      "end\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-- test function\n",
      "function test(dataset)\n",
      "\n",
      "   -- test over given dataset\n",
      "   print('<trainer> on testing Set:')\n",
      "   for t = 1,dataset:size() do\n",
      "      -- get new sample\n",
      "      local input = dataset.data[t]\n",
      "      local target = dataset.labels[t]\n",
      "\n",
      "      -- test sample\n",
      "      local pred = model:forward(input)\n",
      "      confusion:add(pred, target)\n",
      "   end\n",
      "\n",
      "   -- print confusion matrix\n",
      "   print(confusion)\n",
      "   confusion:zero()\n",
      "\n",
      "end\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train(trainData)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test(testData)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}